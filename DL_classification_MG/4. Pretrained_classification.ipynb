{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import silence_tensorflow.auto\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting numpy data\n",
    "\n",
    "path_save = os.path.join(os.path.abspath('.'), 'npy')\n",
    "train_x = np.repeat(np.load(os.path.join(path_save, 'train_img.npy')), 3, axis=-1)\n",
    "test_x = np.repeat(np.load(os.path.join(path_save, 'test_img.npy')), 3, axis=-1)\n",
    "train_y = np.load(os.path.join(path_save, 'train_lab.npy'))\n",
    "test_y = np.load(os.path.join(path_save, 'test_lab.npy'))\n",
    "\n",
    "print('Data shape')\n",
    "print(f'Train img: {train_x.shape} | Train lab: {train_y.shape}')\n",
    "print(f'Test img: {test_x.shape} | Test lab: {test_y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sample\n",
    "n_sample = 5\n",
    "class_dict = {'normal': 0,\n",
    "                'abnormal': 1}\n",
    "\n",
    "for n in range(1, len(train_x), len(train_x)//n_sample):\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(f'{list(class_dict.keys())[train_y[n].argmax()]}')\n",
    "    plt.imshow(train_x[n],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resnet50(inputs, n_class, weights='imagenet'):\n",
    "\n",
    "    input_x = ResNet50(include_top=False, weights=weights, input_tensor=inputs)\n",
    "\n",
    "    for layer in input_x.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "    x = input_x.output\n",
    "    x = GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    ## Fine tunning\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(n_class, activation='softmax', name='output')(x)\n",
    "\n",
    "   \n",
    "    model = Model(inputs = inputs, outputs = x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training classification model using Simple CNN model with data augmentation\n",
    "\n",
    "path_save = os.path.join(os.path.abspath('.'), 'Result', 'model_pretrain')\n",
    "os.makedirs(path_save, exist_ok=True)\n",
    "\n",
    "## parameter setting\n",
    "n_class = 2         \n",
    "imageSize = 512     \n",
    "lr = 0.0001\n",
    "epochs = 50\n",
    "batch = 10\n",
    "loss_function = \"categorical_crossentropy\"\n",
    "\n",
    "## model build\n",
    "input_img = Input(shape=(imageSize,imageSize,3), name='input')\n",
    "\n",
    "model = Resnet50(input_img, n_class)\n",
    "# model.summary()                      # Check model structure\n",
    "\n",
    "\n",
    "## Callback\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(path_save,f'best_model.h5'), \n",
    "                                verbose=1, \n",
    "                                save_weights_only=True, \n",
    "                                save_best_only=True, \n",
    "                                monitor='val_loss', \n",
    "                                save_freq='epoch')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=0, min_delta=0.001, verbose=1)\n",
    "callbacks_list = [reduce_lr, checkpointer]\n",
    "\n",
    "## model compile\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(\n",
    "        optimizer=optimizer, loss=loss_function, metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "## training model\n",
    "model.fit(train_x, train_y,\n",
    "            steps_per_epoch=len(train_x) // batch, epochs=epochs,\n",
    "            validation_split=0.2,\n",
    "            callbacks=callbacks_list,\n",
    "            shuffle=True\n",
    "                        )\n",
    "\n",
    "## saving last model weight\n",
    "model.save_weights(os.path.join(path_save,f'last_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation using test data\n",
    "def change_channel(path_img):\n",
    "    img = np.load(path_img)\n",
    "    img = np.squeeze(img, axis=-1)\n",
    "    img = np.stack((img,)*3, axis=-1)\n",
    "    return img\n",
    "\n",
    "test_x = change_channel(os.path.join(os.path.abspath('.'), 'npy', 'test_img.npy'))\n",
    "print(test_x.shape)\n",
    "test_y = np.load(os.path.join(os.path.abspath('.'), 'npy', 'test_lab.npy'))\n",
    "\n",
    "_loss, _acc = model.evaluate(test_x, test_y, batch_size=10, verbose=1)\n",
    "print('Last model accuracy')\n",
    "print(f'loss: {_loss:0.3f} | accuracy: {_acc:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using best model\n",
    "model.load_weights(os.path.join(path_save,f'best_model.h5'))\n",
    "_loss, _acc = model.evaluate(test_x, test_y, batch_size=10, verbose=1)\n",
    "print('Best model accuracy')\n",
    "print(f'loss: {_loss:0.3f} | accuracy: {_acc:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking fail data\n",
    "test_result = model.predict(test_x, batch_size=10)\n",
    "\n",
    "for a in range(len(test_result)):\n",
    "    if test_result[a].argmax()!=test_y[a].argmax():\n",
    "        plt.title(f'GT: {test_y[a].argmax()} | Result: {test_result[a].argmax()}')\n",
    "        plt.imshow(test_x[a], cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "print(classification_report(test_y.argmax(axis=1), test_result.argmax(axis=1)))\n",
    "\n",
    "# Comufsion matrix 확인\n",
    "\n",
    "test_th = np.where(test_result > 0.5, 1, 0)\n",
    "\n",
    "cm = confusion_matrix(test_y.argmax(axis=1), test_result.argmax(axis=1))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['normal', 'abnormal'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawing_ROCcurve(test_y, test_result, path_save):\n",
    "\n",
    "    def compute_roc_auc(y_true, y_score):\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        return fpr, tpr, auc(fpr, tpr)\n",
    "\n",
    "    n_classes = test_y.shape[-1]\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], roc_auc[i] = compute_roc_auc(test_y[:, i], test_result[:, i])\n",
    "\n",
    "    fpr[\"micro\"], tpr[\"micro\"], roc_auc[\"micro\"] = compute_roc_auc(test_y.ravel(), test_result.ravel())\n",
    "\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "    mean_tpr = np.mean([np.interp(all_fpr, fpr[i], tpr[i]) for i in range(n_classes)], axis=0)\n",
    "\n",
    "    fpr[\"macro\"], tpr[\"macro\"], roc_auc[\"macro\"] = all_fpr, mean_tpr, auc(all_fpr, mean_tpr)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f\"micro-average (auc = {roc_auc['micro']:.2f})\", color=\"maroon\", linestyle=\":\", linewidth=4)\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f\"macro-average (auc = {roc_auc['macro']:.2f})\", color=\"navy\", linestyle=\":\", linewidth=4)\n",
    "\n",
    "    colors = ['blue', 'yellow', 'green', 'red', 'purple', 'orange', 'pink', 'brown', 'gray', 'cyan']\n",
    "    for i, color in zip(range(n_classes), colors[:n_classes]):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, color=color, label=f\"ROC curve (auc = {roc_auc[i]:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=20)\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=20)\n",
    "    plt.title(\"Receiver operating characteristic curves\", fontsize=20)\n",
    "    plt.legend(loc=\"lower right\", fontsize=14)\n",
    "    plt.savefig(f'{path_save}/ROC_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_ROCcurve(test_y, test_result, path_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JWSeo_ptf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
