{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import silence_tensorflow.auto\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting numpy data\n",
    "\n",
    "path_save = os.path.join(os.path.abspath('.'), 'npy')\n",
    "train_x = np.load(os.path.join(path_save, 'train_img.npy'))\n",
    "test_x = np.load(os.path.join(path_save, 'test_img.npy'))\n",
    "train_y = np.load(os.path.join(path_save, 'train_lab.npy'))\n",
    "test_y = np.load(os.path.join(path_save, 'test_lab.npy'))\n",
    "\n",
    "# split for validation set\n",
    "train_x, valid_x, train_y, valid_y= train_test_split(train_x, train_y, test_size=0.2, random_state=4, stratify= train_y)\n",
    "\n",
    "print('Data shape')\n",
    "print(f'Train img: {train_x.shape} | Train lab: {train_y.shape}')\n",
    "print(f'valid img: {valid_x.shape} | valid lab: {valid_y.shape}')\n",
    "print(f'Test img: {test_x.shape} | Test lab: {test_y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ImageDataGenerator\n",
    "## Checking output data\n",
    "train_gen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    rotation_range=0.25,\n",
    "    zoom_range=[1.0, 1.5]\n",
    ")\n",
    "train_generator = train_gen.flow(train_x, train_y, shuffle=True, batch_size=4)\n",
    "augs = train_generator.__getitem__(7)\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "for i, img in enumerate(augs[0]):\n",
    "    plt.subplot(4, 8, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simple_CNNmodel(input_img, base = 32, scale = 2, n_layers = 6):\n",
    "\n",
    "    x = input_img\n",
    "\n",
    "    for n in range(n_layers):\n",
    "        x = Conv2D(((scale)**n)*base, 3, activation=None, padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation='relu')(x)\n",
    "        x = Conv2D(((scale)**n)*base, 3, activation=None, padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(activation='relu')(x)\n",
    "        if n != n_layers:\n",
    "            x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    out = GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "    out = Dense(128, activation=\"relu\")(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    \n",
    "    out = Dense(64, activation=\"relu\")(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dropout(0.3)(out)\n",
    "    \n",
    "    out = Dense(n_class, activation=\"softmax\")(out)\n",
    "    model = Model(inputs=input_img, outputs=out)\n",
    "    \n",
    "    return model\n",
    "# Training classification model using Simple CNN model with data augmentation\n",
    "\n",
    "path_save = os.path.join(os.path.abspath('.'), 'Result', 'model_simple_augmentation')\n",
    "os.makedirs(path_save, exist_ok=True)\n",
    "\n",
    "## parameter setting\n",
    "n_class = 2         \n",
    "imageSize = 512     \n",
    "lr = 0.0001\n",
    "epochs = 50\n",
    "batch = 10\n",
    "loss_function = \"categorical_crossentropy\"\n",
    "\n",
    "## model build\n",
    "input_img = Input(shape=(imageSize,imageSize,1))\n",
    "\n",
    "model = Simple_CNNmodel(input_img, n_class)\n",
    "model.summary()         # Check model structure\n",
    "\n",
    "## Data generator for augmentation\n",
    "train_gen = ImageDataGenerator(\n",
    "    width_shift_range=0.2,       # 이미지 너비의 20% 범위 내에서 임의로 좌우 이동\n",
    "    height_shift_range=0.2,     # 이미지 높이의 20% 범위 내에서 임의로 좌우 이동\n",
    "    horizontal_flip=True,       # 수평 뒤집기\n",
    "    vertical_flip = True,       # 수직 뒤집기\n",
    "    rotation_range=0.25,        # 중심축을 기준으로 최대 ±0.25도 회전\n",
    "    zoom_range=[0.5, 1.5]       # 최대 0.5배 축소부터 1.5배 확대\n",
    ")\n",
    "valid_gen = ImageDataGenerator()        \n",
    "\n",
    "\n",
    "## Callback\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(path_save,f'best_model.h5'), \n",
    "                                verbose=1, \n",
    "                                save_weights_only=True, \n",
    "                                save_best_only=True, \n",
    "                                monitor='val_loss', \n",
    "                                save_freq='epoch')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=0, min_delta=0.001, verbose=1)\n",
    "callbacks_list = [reduce_lr, checkpointer]\n",
    "\n",
    "## model compile\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(\n",
    "        optimizer=optimizer, loss=loss_function, metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "## training model\n",
    "model.fit(train_gen.flow(train_x, train_y, shuffle=True, batch_size=batch), \n",
    "            steps_per_epoch=len(train_x) // batch, \n",
    "            epochs=epochs,\n",
    "            validation_data=valid_gen.flow(valid_x, valid_y, batch_size=batch, shuffle=False),\n",
    "            callbacks=callbacks_list\n",
    "                        )\n",
    "\n",
    "## saving last model weight\n",
    "model.save_weights(os.path.join(path_save,f'last_model.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation using train data\n",
    "_loss, _acc = model.evaluate(train_x, train_y, batch_size=10, verbose=1)\n",
    "print('Last model accuracy')\n",
    "print(f'loss: {_loss:0.3f} | accuracy: {_acc:0.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation using test data\n",
    "_loss, _acc = model.evaluate(test_x, test_y, batch_size=10, verbose=1)\n",
    "print('Last model accuracy')\n",
    "print(f'loss: {_loss:0.3f} | accuracy: {_acc:0.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using best model\n",
    "model.load_weights(os.path.join(path_save,f'best_model.h5'))\n",
    "_loss, _acc = model.evaluate(test_x, test_y, batch_size=10, verbose=1)\n",
    "print('Best model accuracy')\n",
    "print(f'loss: {_loss:0.3f} | accuracy: {_acc:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking fail data\n",
    "test_result = model.predict(test_x, batch_size=10)\n",
    "\n",
    "for a in range(len(test_result)):\n",
    "    if test_result[a].argmax()!=test_y[a].argmax():\n",
    "        plt.title(f'GT: {test_y[a].argmax()} | Result: {test_result[a].argmax()}')\n",
    "        plt.imshow(test_x[a], cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "print(classification_report(test_y.argmax(axis=1), test_result.argmax(axis=1)))\n",
    "\n",
    "# Comufsion matrix 확인\n",
    "\n",
    "test_th = np.where(test_result > 0.5, 1, 0)\n",
    "\n",
    "cm = confusion_matrix(test_y.argmax(axis=1), test_result.argmax(axis=1))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['normal', 'abnormal'])\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
