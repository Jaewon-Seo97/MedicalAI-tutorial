{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import silence_tensorflow.auto\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data name\n",
    "path_data = os.path.join('/home/user/workdir/notices/data', 'breast')\n",
    "path_abimg = os.path.join(path_data, 'image', 'abnormal')\n",
    "path_nrimg = os.path.join(path_data, 'image', 'normal')\n",
    "\n",
    "abnameList = sorted(glob.glob(os.path.join(path_abimg, '*.dcm')))\n",
    "nrnameList = sorted(glob.glob(os.path.join(path_nrimg, '*.dcm')))\n",
    "\n",
    "nameList = abnameList+nrnameList\n",
    "labList = [1 if n < len(abnameList) else 0 for n in range(len(nameList))]\n",
    "\n",
    "print(f'Abnormal: {len(abnameList)}')\n",
    "print(f'Normal: {len(nrnameList)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validation, and test data\n",
    "trainnameList, testnameList, trainlabList, testlabList= train_test_split(nameList, labList, test_size=0.1, random_state=4, stratify= labList)\n",
    "trainnameList, validnameList, trainlabList, validlabList= train_test_split(trainnameList, trainlabList, test_size=0.1, random_state=4, stratify= trainlabList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting preprocessing data\n",
    "clahe = cv2.createCLAHE(clipLimit = 2.0, tileGridSize = (18,18))\n",
    "\n",
    "def getting_img(path_img, imageSize):\n",
    "    img = sitk.ReadImage(path_img)\n",
    "    img = sitk.GetArrayFromImage(img)[0]\n",
    "    \n",
    "    img = clahe.apply(img)\n",
    "    img = img-img.min()/(img.max()-img.min())\n",
    "\n",
    "    img = cv2.resize(img, (imageSize, imageSize), interpolation=cv2.INTER_AREA)\n",
    "    img = np.stack((img,)*3, axis=-1)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_generator(nameList, imageSize):\n",
    "    # Iterate over all the image paths\n",
    "    for name in nameList:\n",
    "\n",
    "        img = getting_img(name, imageSize)\n",
    "        if 'AN' in os.path.basename(name):\n",
    "            lab = np.asarray([0, 1])\n",
    "        else:\n",
    "            lab = np.asarray([1, 0])\n",
    "        \n",
    "        yield img, lab\n",
    "\n",
    "def img_batch_generator(nameList, imageSize, batchsize=10):\n",
    "    while True:\n",
    "        ig = img_generator(nameList, imageSize)\n",
    "        batch_img, batch_lab = [], []\n",
    "        \n",
    "        for img, lab in ig:\n",
    "            # Add the image and label to the batch\n",
    "            batch_img.append(img)\n",
    "            batch_lab.append(lab)\n",
    "            \n",
    "            # If we've reached our batchsize, yield the batch and reset\n",
    "            if len(batch_img) == batchsize:\n",
    "                yield np.stack(batch_img, axis=0), np.stack(batch_lab, axis=0)\n",
    "                batch_img, batch_lab = [], []\n",
    "        \n",
    "        # If we have an nonempty batch left, yield it out and reset\n",
    "        if len(batch_img) != 0:\n",
    "            yield np.stack(batch_img, axis=0), np.stack(batch_lab, axis=0)\n",
    "            batch_img, batch_lab = [], [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resnet50(inputs, n_class, weights='imagenet'):\n",
    "\n",
    "    input_x = ResNet50(include_top=False, weights=weights, input_tensor=inputs)\n",
    "\n",
    "    for layer in input_x.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "    x = input_x.output\n",
    "    x = GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    ## Fine tunning\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(n_class, activation='softmax', name='output')(x)\n",
    "\n",
    "   \n",
    "    model = Model(inputs = inputs, outputs = x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training classification model using Simple CNN model with data augmentation\n",
    "\n",
    "path_save = os.path.join(os.path.abspath('.'), 'Result', 'model_pretrain')\n",
    "os.makedirs(path_save, exist_ok=True)\n",
    "\n",
    "## parameter setting\n",
    "n_class = 2         \n",
    "imageSize = 512     \n",
    "lr = 0.0001\n",
    "epochs = 50\n",
    "batch = 10\n",
    "loss_function = \"categorical_crossentropy\"\n",
    "\n",
    "## model build\n",
    "input_img = Input(shape=(imageSize,imageSize,3), name='input')\n",
    "\n",
    "model = Resnet50(input_img, n_class)\n",
    "# model.summary()                      # Check model structure\n",
    "\n",
    "# Setting generator\n",
    "train_gen = img_batch_generator(trainnameList, imageSize, batchsize=batch)\n",
    "valid_gen = img_batch_generator(validnameList, imageSize, batchsize=batch)\n",
    "\n",
    "\n",
    "## Callback\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(path_save,f'best_model.h5'), \n",
    "                                verbose=1, \n",
    "                                save_weights_only=True, \n",
    "                                save_best_only=True, \n",
    "                                monitor='val_loss', \n",
    "                                save_freq='epoch')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=0, min_delta=0.001, verbose=1)\n",
    "callbacks_list = [reduce_lr, checkpointer]\n",
    "\n",
    "## model compile\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(\n",
    "        optimizer=optimizer, loss=loss_function, metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "## training model\n",
    "model.fit(train_gen, \n",
    "            steps_per_epoch=len(trainnameList) // batch, \n",
    "            epochs=epochs,\n",
    "            validation_data=valid_gen,\n",
    "            validation_steps=len(validnameList)//batch,\n",
    "            callbacks=callbacks_list\n",
    "                        )\n",
    "\n",
    "## saving last model weight\n",
    "model.save_weights(os.path.join(path_save,f'last_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation using test data\n",
    "def change_channel(path_img):\n",
    "    img = np.load(path_img)\n",
    "    img = np.squeeze(img, axis=-1)\n",
    "    img = np.stack((img,)*3, axis=-1)\n",
    "    return img\n",
    "\n",
    "test_x = change_channel(os.path.join(os.path.abspath('.'), 'npy', 'test_img.npy'))\n",
    "print(test_x.shape)\n",
    "test_y = np.load(os.path.join(os.path.abspath('.'), 'npy', 'test_lab.npy'))\n",
    "\n",
    "_loss, _acc = model.evaluate(test_x, test_y, batch_size=10, verbose=1)\n",
    "print('Last model accuracy')\n",
    "print(f'loss: {_loss:0.3f} | accuracy: {_acc:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using best model\n",
    "model.load_weights(os.path.join(path_save,f'best_model.h5'))\n",
    "_loss, _acc = model.evaluate(test_x, test_y, batch_size=10, verbose=1)\n",
    "print('Best model accuracy')\n",
    "print(f'loss: {_loss:0.3f} | accuracy: {_acc:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking fail data\n",
    "test_result = model.predict(test_x, batch_size=10)\n",
    "\n",
    "for a in range(len(test_result)):\n",
    "    if test_result[a].argmax()!=test_y[a].argmax():\n",
    "        plt.title(f'GT: {test_y[a].argmax()} | Result: {test_result[a].argmax()}')\n",
    "        plt.imshow(test_x[a], cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "print(classification_report(test_y.argmax(axis=1), test_result.argmax(axis=1)))\n",
    "\n",
    "# Comufsion matrix 확인\n",
    "\n",
    "test_th = np.where(test_result > 0.5, 1, 0)\n",
    "\n",
    "cm = confusion_matrix(test_y.argmax(axis=1), test_result.argmax(axis=1))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=['normal', 'abnormal'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawing_ROCcurve(test_y, test_result, path_save):\n",
    "\n",
    "    def compute_roc_auc(y_true, y_score):\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        return fpr, tpr, auc(fpr, tpr)\n",
    "\n",
    "    n_classes = test_y.shape[-1]\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], roc_auc[i] = compute_roc_auc(test_y[:, i], test_result[:, i])\n",
    "\n",
    "    fpr[\"micro\"], tpr[\"micro\"], roc_auc[\"micro\"] = compute_roc_auc(test_y.ravel(), test_result.ravel())\n",
    "\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "    mean_tpr = np.mean([np.interp(all_fpr, fpr[i], tpr[i]) for i in range(n_classes)], axis=0)\n",
    "\n",
    "    fpr[\"macro\"], tpr[\"macro\"], roc_auc[\"macro\"] = all_fpr, mean_tpr, auc(all_fpr, mean_tpr)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f\"micro-average (auc = {roc_auc['micro']:.2f})\", color=\"maroon\", linestyle=\":\", linewidth=4)\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f\"macro-average (auc = {roc_auc['macro']:.2f})\", color=\"navy\", linestyle=\":\", linewidth=4)\n",
    "\n",
    "    colors = ['blue', 'yellow', 'green', 'red', 'purple', 'orange', 'pink', 'brown', 'gray', 'cyan']\n",
    "    for i, color in zip(range(n_classes), colors[:n_classes]):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, color=color, label=f\"ROC curve (auc = {roc_auc[i]:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=20)\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=20)\n",
    "    plt.title(\"Receiver operating characteristic curves\", fontsize=20)\n",
    "    plt.legend(loc=\"lower right\", fontsize=14)\n",
    "    plt.savefig(f'{path_save}/ROC_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_ROCcurve(test_y, test_result, path_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0642c3d6a6210ac9dcf3acf256e659a1278243731471d18f7b51f84222164b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
