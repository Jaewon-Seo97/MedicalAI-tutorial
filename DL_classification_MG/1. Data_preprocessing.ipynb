{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>목표</h1>\n",
    "\n",
    "- 학습 성능을 향상시키기 위한 전처리 방법 중 하나로써 CLAHE 영상 처리를 진행함.\n",
    "- 학습 네트워크의 입력 데이터 형태에 맞게 데이터를 생성함.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> CLAHE(Contrast Limited Adaptive Histogram Equalization): 대비 제한 적응 히스토그램 평활화 </h4>\n",
    "    \n",
    "- 영상의 대조도를 높이기 위한 전처리 적용\n",
    "- Histogram equalization(HE): 각각의 값이 전체 분포에 차지하는 비중에 따라 분포를 재분배하므로 명암 대비를 개선하는 데 효과적\n",
    "\n",
    "    <img src=\"fig_source/clahe.png\"></img>\n",
    "    - CLAHE: 이미지를 일정한 영역(tileGridSize 파라미터)으로 나누어 평탄화를 적용\n",
    "    - 일정한 영역 내에서 극단적으로 어둡거나 밝은 부분이 있으면 노이즈가 발생\n",
    "    - 어떤 영역이든 지정된 제한 값(clipLimit)을 넘으면 그 픽셀은 다른 영역에 균일하게 배분하여 적용\n",
    "\n",
    "- CLAHE의 주요 매개변수: clipLimit와 tileGridSize\n",
    "1. Clip Limit (clipLimit)\n",
    "    - clipLimit는 히스토그램이 클립되는 수준을 결정하는 매개변수. 기본 AHE에서는 히스토그램 평활화가 매우 큰 대비를 초래하지만, CLAHE에서는 클립 한계를 설정하여 과도한 대비를 방지함.\n",
    "    - 낮은 clipLimit: 대비가 적당히 개선됨. 노이즈가 덜 강화됨.\n",
    "    - 높은 clipLimit: 대비가 크게 개선됨. 노이즈도 함께 강조될 수 있음.\n",
    "\n",
    "2. Tile Grid Size (tileGridSize)\n",
    "    - tileGridSize는 이미지가 타일로 나누어지는 크기를 결정하는 매개변수. CLAHE는 이미지를 작은 타일로 나누고, 각 타일에 대해 히스토그램 평활화를 수행한 후 타일 간의 경계를 부드럽게 연결함.\n",
    "\n",
    "    - 작은 tileGridSize: 국소적인 대비가 크게 개선됨. 타일 경계가 눈에 띌 수 있음.\n",
    "    - 큰 tileGridSize: 전체적인 대비 개선 효과가 줄어듦. 타일 경계가 덜 눈에 띔.\n",
    "\n",
    "* 일반적인 유방 X선 영상에서의 병변의 대비 향상을 위하여 전처리로 CLAHE를 사용하며, 경험적인 수치로 선정함.\n",
    "    - 한 연구에서 여러 변수의 비교 중 12.0의 ClipLimit와 8x8의 tilegrid를 적용했을 때 가장 높은 성능을 보임.\n",
    "        - Jiang Z, Gandomkar Z, Trieu PD, Tavakoli Taba S, Barron ML, Obeidy P, Lewis SJ. Evaluating Recalibrating AI Models for Breast Cancer Diagnosis in a New Context: Insights from Transfer Learning, Image Enhancement and High-Quality Training Data Integration. Cancers. 2024; 16(2):322. https://doi.org/10.3390/cancers16020322\n",
    "        => Australian mammographic database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data name\n",
    "path_data = os.path.join('/home/user/workdir/notices/data', 'breast')\n",
    "\n",
    "path_abimg = os.path.join(path_data, 'image', 'abnormal')\n",
    "path_nrimg = os.path.join(path_data, 'image', 'normal')\n",
    "\n",
    "abnameList = sorted(glob.glob(os.path.join(path_abimg, '*.dcm')))\n",
    "nrnameList = sorted(glob.glob(os.path.join(path_nrimg, '*.dcm')))\n",
    "\n",
    "nameList = abnameList+nrnameList\n",
    "labList = [1 if n < len(abnameList) else 0 for n in range(len(nameList))]\n",
    "\n",
    "print(f'Abnormal: {len(abnameList)}')\n",
    "print(f'Normal: {len(nrnameList)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing in a sample data\n",
    "sample_num = 5\n",
    "abname = abnameList[sample_num]\n",
    "print(f'Sample name: {abname}')\n",
    "\n",
    "## Checking a original sample image\n",
    "img = sitk.ReadImage(os.path.join(abname))\n",
    "img = sitk.GetArrayFromImage(img)[0]\n",
    "\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OpenCV(cv2) library를 활용한 CLAHE 전처리 적용 방법\n",
    "fixed_clip = 2.0\n",
    "fixed_tile = 16\n",
    "clahe = cv2.createCLAHE(clipLimit = fixed_clip, tileGridSize = (fixed_tile,fixed_tile))\n",
    "img_clahe = clahe.apply(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking tileGridSize\n",
    "# Apply CLAHE with different tile grid sizes\n",
    "clahe_1 = cv2.createCLAHE(clipLimit=fixed_clip, tileGridSize=(2, 2)).apply(img)\n",
    "clahe_2 = cv2.createCLAHE(clipLimit=fixed_clip, tileGridSize=(16, 16)).apply(img)\n",
    "clahe_3 = cv2.createCLAHE(clipLimit=fixed_clip, tileGridSize=(100, 100)).apply(img)\n",
    "\n",
    "# Plot results\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "axs[0].imshow(img, cmap='gray')\n",
    "axs[0].set_title('Original Image')\n",
    "axs[1].imshow(clahe_1, cmap='gray')\n",
    "axs[1].set_title('CLAHE tileGridSize=(2, 2)')\n",
    "axs[2].imshow(clahe_2, cmap='gray')\n",
    "axs[2].set_title('CLAHE tileGridSize=(16, 16)')\n",
    "axs[3].imshow(clahe_3, cmap='gray')\n",
    "axs[3].set_title('CLAHE tileGridSize=(100, 100)')\n",
    "plt.savefig('clahe_comparison_fixedClipLimit.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking tileGridSize\n",
    "# Apply CLAHE with different tile grid sizes\n",
    "clahe_1 = cv2.createCLAHE(clipLimit=0.01, tileGridSize=(fixed_tile, fixed_tile)).apply(img)\n",
    "clahe_2 = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(fixed_tile, fixed_tile)).apply(img)\n",
    "clahe_3 = cv2.createCLAHE(clipLimit=40.0, tileGridSize=(fixed_tile, fixed_tile)).apply(img)\n",
    "\n",
    "# Plot results\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "axs[0].imshow(img, cmap='gray')\n",
    "axs[0].set_title('Original Image')\n",
    "axs[1].imshow(clahe_1, cmap='gray')\n",
    "axs[1].set_title('CLAHE clipLimit=0.01')\n",
    "axs[2].imshow(clahe_2, cmap='gray')\n",
    "axs[2].set_title('CLAHE clipLimit=2.0')\n",
    "axs[3].imshow(clahe_3, cmap='gray')\n",
    "axs[3].set_title('CLAHE clipLimit=40.0')\n",
    "plt.savefig('clahe_comparison_fixedTileGrid.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data\n",
    "## clahe 설정\n",
    "clahe = cv2.createCLAHE(clipLimit = fixed_clip, tileGridSize = (fixed_tile,fixed_tile)) \n",
    "\n",
    "## 데이터 로드 및 clahe 적용 함수 설정\n",
    "def getting_img(path_img, imageSize):\n",
    "    # loading image from dicom format\n",
    "    img = sitk.ReadImage(path_img)\n",
    "    img = sitk.GetArrayFromImage(img)[0]\n",
    "    \n",
    "    img = clahe.apply(img)\n",
    "    img = (img-img.min())/(img.max()-img.min())  # min-max normalization\n",
    "\n",
    "    img = cv2.resize(img, (imageSize, imageSize), interpolation=cv2.INTER_AREA)\n",
    "    img = np.expand_dims(img, axis=0)   # expanding image dimension for stacking data\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving grayscale images as numpy format\n",
    "\n",
    "n_class = 2         # Normal: 0 | Abnormal: 1 \n",
    "imageSize = 512     # 임의 설정값. \n",
    "\n",
    "os.makedirs(os.path.join(os.path.abspath('.'), 'npy'), exist_ok=True)           # Setting saving path\n",
    "\n",
    "\n",
    "## Making empty array for stacking all data\n",
    "array_img = np.ndarray((0,imageSize,imageSize), np.float32)\n",
    "array_lab = np.ndarray((0,n_class))\n",
    "\n",
    "## Loading and Stacking data\n",
    "for name in tqdm.tqdm(nameList):\n",
    "\n",
    "    img = getting_img(name, imageSize)   # Getting image data\n",
    "    \n",
    "    # Making label data\n",
    "    if 'AN' in os.path.basename(name):   # abnormal label: 1\n",
    "        lab = np.asarray([0, 1])\n",
    "    else:\n",
    "        lab = np.asarray([1, 0])\n",
    "\n",
    "    array_img = np.concatenate([array_img, img], axis=0)    # Stacking data\n",
    "    array_lab = np.concatenate([array_lab, np.expand_dims(lab, axis=0)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Image shape: {array_img.shape} | Label shape: {array_lab.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data shape\n",
    "array_img = np.expand_dims(array_img, axis=-1)      # input shape에 맞춰줌. (n_images, image_height, image_width, channel)\n",
    "print(f'Image shape: {array_img.shape} | Label shape: {array_lab.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving data for numpy format\n",
    "### => 학습에 활용될 데이터 미리 저장\n",
    "### => 학습용 데이터: Train, 성능 검증용 데이터 Test\n",
    "train_x, test_x, train_y, test_y= train_test_split(array_img, array_lab, test_size=0.1, random_state=4, stratify= array_lab)\n",
    "\n",
    "path_save = os.path.join(os.path.abspath('.'), 'npy')\n",
    "os.makedirs(path_save, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(path_save, 'train_img.npy'), train_x)\n",
    "np.save(os.path.join(path_save, 'test_img.npy'), test_x)\n",
    "np.save(os.path.join(path_save, 'train_lab.npy'), train_y)\n",
    "np.save(os.path.join(path_save, 'test_lab.npy'), test_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JWSeo_ptf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
