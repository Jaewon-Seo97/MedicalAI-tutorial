{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== ML Models ==============\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    ExtraTreesClassifier,\n",
    ")\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# ============== Data Preprocessing ==============\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# ============== Model Evaluation and Tuning ==============\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGSIZE = (15, 9)\n",
    "FONTSIZE = 15\n",
    "\n",
    "class MLClassifierPipeline:\n",
    "    \"\"\"\n",
    "    A pipeline for training multiple machine learning classification models,\n",
    "    comparing their performance, and selecting the best model.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, seed):\n",
    "        \"\"\"\n",
    "        Initialize the pipeline with data and optional random seed.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.models = {}  # Dictionary for trained models\n",
    "        self.accuracies = {}  # Dictionary accuracies\n",
    "        self.seed = seed\n",
    "\n",
    "    def standardize_data(self):\n",
    "        scaler = RobustScaler()  # Initialize scaler\n",
    "        self.X = scaler.fit_transform(self.X)  # Fit and transform the data\n",
    "\n",
    "    def split_data(self, test_size=0.25, random_state=None):\n",
    "        \"\"\"\n",
    "        Splits the data into training and test sets.\n",
    "        If balance_data is True, applies SMOTE to balance the training data.\n",
    "        \"\"\"\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "\n",
    "            \n",
    "    def train_models(self):\n",
    "        \"\"\"\n",
    "        Trains various classification models and stores their accuracies.\n",
    "        \"\"\"\n",
    "        self.models['Logistic Regression'] = LogisticRegression()\n",
    "        self.models['K-Nearest Neighbors'] = KNeighborsClassifier()\n",
    "        self.models['Decision Tree'] = DecisionTreeClassifier()\n",
    "        self.models['Random Forest'] = RandomForestClassifier()\n",
    "        self.models['SVM'] = SVC()\n",
    "        self.models['Gradient Boosting'] = GradientBoostingClassifier()\n",
    "        self.models['AdaBoost'] = AdaBoostClassifier()\n",
    "        self.models['LDA'] = LinearDiscriminantAnalysis()\n",
    "        self.models['QDA'] = QuadraticDiscriminantAnalysis()\n",
    "        self.models['Naive Bayes'] = GaussianNB()\n",
    "        self.models['Extra Trees'] = ExtraTreesClassifier()\n",
    "        self.models['SGD'] = SGDClassifier()\n",
    "        self.models['Perceptron'] = Perceptron()\n",
    "        self.models['XGBoost'] = XGBClassifier()\n",
    "        self.models['LightGBM'] = LGBMClassifier(verbose=-1)\n",
    "        self.models['Neural Network'] = MLPClassifier(max_iter=1000, learning_rate_init=0.002,  early_stopping=True)\n",
    "\n",
    "        # Train each model and compute its accuracy\n",
    "        for name, model in self.models.items():\n",
    "            np.random.seed(self.seed)\n",
    "            model.fit(self.X_train, self.y_train)           # Train model\n",
    "            y_pred = model.predict(self.X_test)             # Predictions\n",
    "            accuracy = accuracy_score(self.y_test, y_pred)  # Accuracy\n",
    "            self.accuracies[name] = accuracy                # Store accuracy\n",
    "\n",
    "    def plot_accuracies(self, palette='Purples_r', figsize=FIGSIZE):\n",
    "\n",
    "        # Sort accuracies in descending order\n",
    "        self.sorted_accuracies = {\n",
    "            k: v for k, v in sorted(self.accuracies.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "        # Plot accuracies\n",
    "        plt.figure(figsize=figsize)\n",
    "        ax = sns.barplot(y=list(self.sorted_accuracies.keys()),\n",
    "                         x=list(self.sorted_accuracies.values()),\n",
    "                         palette=palette, orient='h')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Model Accuracy Comparison')\n",
    "\n",
    "        for p, value in zip(ax.patches, list(self.sorted_accuracies.values())):\n",
    "            ax.annotate(f\"{value:.3f}\", (p.get_width(), p.get_y() + p.get_height() / 2),\n",
    "                      ha='left', va='center', xytext=(5, 0), textcoords='offset points', fontsize=10)\n",
    "        plt.grid(alpha=0.25)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_confusion_matrix(self, figsize=(11, 12), cmap='Blues', fontsize=12):\n",
    "        # Getting best model\n",
    "        _, best_model, _ = self.get_best_model()\n",
    "        \n",
    "        # Generate predictions\n",
    "        self.y_pred = best_model.predict(self.X_test)\n",
    "\n",
    "        # Generate the confusion matrix\n",
    "        cm = confusion_matrix(self.y_test, self.y_pred)\n",
    "        \n",
    "        # Plot the confusion matrix\n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.heatmap(cm, annot=True, fmt='g', cmap=cmap, annot_kws={\"size\": fontsize}, cbar=False)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.grid(alpha=0)\n",
    "        plt.show()\n",
    "\n",
    "    def get_best_model(self):\n",
    "        # Find model with highest accuracy\n",
    "        best_model_name = max(self.accuracies, key=self.accuracies.get)\n",
    "        best_model = self.models[best_model_name]\n",
    "\n",
    "        return best_model_name, best_model, self.accuracies[best_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "df = pd.read_csv(\"data/Radiomic_features_all.csv\" , sep = \",\")\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameter\n",
    "n_fold = 5\n",
    "rand_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data\n",
    "\n",
    "## Removing missing value\n",
    "df = df.dropna()\n",
    "\n",
    "## Removing duplicate data\n",
    "df.drop_duplicates(subset=None, keep='first', ignore_index=False, inplace=True)\n",
    "\n",
    "## Data split\n",
    "X = df.drop('label', axis=1).values  # Features\n",
    "Y = df['label'].values.astype(np.uint8)  # Target variable\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = MLClassifierPipeline(X, Y, rand_seed)\n",
    "\n",
    "# data prep\n",
    "pipeline.standardize_data()\n",
    "pipeline.split_data(test_size=0.25, random_state=rand_seed)\n",
    "\n",
    "# Train and evaluate models\n",
    "pipeline.train_models()\n",
    "\n",
    "# Plot accuracies\n",
    "pipeline.plot_accuracies('Blues_r')\n",
    "\n",
    "# Get the best model\n",
    "best_model_name, best_model, best_accuracy = pipeline.get_best_model()\n",
    "print(best_model_name, best_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JWSeo_ptf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
